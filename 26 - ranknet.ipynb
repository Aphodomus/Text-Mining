{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RankNet Text Ranking**\n",
    "Rankeamento textual basicamente é o processo de ordenar texto a partir de algum critério de relevância. Seu objetivo é gerar uma lista ordenada de textos em resposta a uma consulta específica. Temos uma coleção de textos e uma consulta, e vamos retornar ela ordenado.\n",
    "\n",
    "<div align=\"center\" style=\"margin-top: 40px;\">\n",
    "    <img src=\"./images/rank.png\" alt=\"Alt text\" width=\"800\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Vector Space Ranking**\n",
    "Baseado em espaço vetorial, tanto o documento quanto a consulta, e para cada par documento e consulta, a similaridade de cosseno entre eles vai representar a importância. O quão relevante o documento é em relação a consulta, se o que a consulta quer realmente é de acordo com o documento.\n",
    "\n",
    "<div align=\"center\" style=\"margin-top: 40px;\">\n",
    "    <img src=\"./images/vector-space.png\" alt=\"Alt text\" width=\"800\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "D1 = 'Machine learning teaches machine how to learn'\n",
    "D2 = 'Machine translation is my favorite subject'\n",
    "D3 = 'Term frequency and inverse document frequency is important'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Text Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learning teaches machine how to learn\n",
      "machine translation is my favorite subject\n",
      "term frequency and inverse document frequency is important\n"
     ]
    }
   ],
   "source": [
    "def normalize_document(document):\n",
    "    return document.lower()\n",
    "\n",
    "D1 = normalize_document(D1)\n",
    "D2 = normalize_document(D2)\n",
    "D3 = normalize_document(D3)\n",
    "\n",
    "print(D1)\n",
    "print(D2)\n",
    "print(D3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_frequency(term, document):\n",
    "    doc = document.split()\n",
    "    return doc.count(term.lower()) / float(len(doc))\n",
    "\n",
    "def inverse_document_frequency(term, document):\n",
    "    count = 0\n",
    "    \n",
    "    for doc in documents:\n",
    "        if term.lower() in doc.lower().split():\n",
    "            count += 1\n",
    "    \n",
    "    if count > 0:\n",
    "        return 1.0 + math.log(float(len(documents)) / count)\n",
    "    else:\n",
    "        return 1.0\n",
    "    \n",
    "# tf-idf of a term in a document\n",
    "def tf_idf(term, document, documents):\n",
    "    tf = term_frequency(term, document)\n",
    "    idf = inverse_document_frequency(term, documents)\n",
    "    return tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine: 1.4054651081081644\n",
      "learning: 2.09861228866811\n",
      "teaches: 2.09861228866811\n",
      "machine: 1.4054651081081644\n",
      "how: 2.09861228866811\n",
      "to: 2.09861228866811\n",
      "learn: 2.09861228866811\n"
     ]
    }
   ],
   "source": [
    "documents = [D1, D2, D3]\n",
    "\n",
    "for term in D1.split():\n",
    "    print('{}: {}'.format(term, inverse_document_frequency(term, documents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine: 0.4015614594594755\n",
      "learning: 0.2998017555240157\n",
      "teaches: 0.2998017555240157\n",
      "machine: 0.4015614594594755\n",
      "how: 0.2998017555240157\n",
      "to: 0.2998017555240157\n",
      "learn: 0.2998017555240157\n"
     ]
    }
   ],
   "source": [
    "for term in D1.split(' '):\n",
    "    print('{}: {}'.format(term, tf_idf(term, D1, documents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query document 0, similarity 0.7252786189058528\n",
      "Query document 1, similarity 0.4279929226831737\n",
      "Query document 2, similarity 0.639070441396375\n"
     ]
    }
   ],
   "source": [
    "query = 'machine learning document'\n",
    "\n",
    "def generate_vectors(query, documents):\n",
    "    tf_idf_matrix = np.zeros((len(query.split()), len(documents)))\n",
    "    \n",
    "    for i, s in enumerate(query.lower().split()):\n",
    "        idf = inverse_document_frequency(s, documents)\n",
    "        \n",
    "        for j, doc in enumerate(documents):\n",
    "            tf_idf_matrix[i][j] = idf * term_frequency(s, doc)\n",
    "    \n",
    "    return tf_idf_matrix\n",
    "\n",
    "tf_idf_matrix = generate_vectors(query, documents)\n",
    "\n",
    "def word_count(s):\n",
    "    counts = dict()\n",
    "    words = s.lower().split()\n",
    "    \n",
    "    for word in words:\n",
    "        if word in counts:\n",
    "            counts[word] += 1\n",
    "        else:\n",
    "            counts[word] = 1\n",
    "            \n",
    "    return counts\n",
    "\n",
    "def build_query_vector(query, documents):\n",
    "    count = word_count(query)\n",
    "    vector = np.zeros((len(count), 1))\n",
    "    \n",
    "    for i, word in enumerate(query.lower().split()):\n",
    "        vector[i] = float(count[word]) / len(count) * inverse_document_frequency(word, documents)\n",
    "        \n",
    "    return vector\n",
    "\n",
    "query_vector = build_query_vector(query, documents)\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    return np.dot(v1, v2) / float(LA.norm(v1) * LA.norm(v2))\n",
    "\n",
    "def compute_relevance(query, documents):\n",
    "    for i, doc in enumerate(documents):\n",
    "        similarity = cosine_similarity(tf_idf_matrix[:,i].reshape(1, len(tf_idf_matrix)), query_vector)\n",
    "        print('Query document {}, similarity {}'.format(i, float(similarity[0])))\n",
    "        \n",
    "compute_relevance(query, documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Learning to Rank**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
