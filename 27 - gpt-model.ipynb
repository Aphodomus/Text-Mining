{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GPT (Generative Pre-trained Transformer)**\n",
    "Fazem parte de uma família de LLMs (Large Language Models) treinada usando aprendizagem profunda (DL) para produzir texto semelhante ao produzido por humanos.\n",
    "Para treinar um GPT, precisamos de um Word Embeddings, ou seja vetores de palavras construídos previamente, existem diferentes abordagens para construir esses vetores de palavras, um exemplo de representaçãom vetorial de 3 palavras diferentes:\n",
    "\n",
    "<div align=\"center\" style=\"margin-top: 40px;\">\n",
    "    <img src=\"./images/example.png\" alt=\"Alt text\" width=\"800\"/>\n",
    "</div>\n",
    "\n",
    "- Observe que o vetor \"chair\" é bem diferente dos vetores \"cat\" e \"dog\".\n",
    "- Os Word Embeddings camptam semântica por trás das palavras, e essa semântica é usada para treinar a GPT."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
