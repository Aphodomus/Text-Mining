{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Count Vector**\n",
    "No one hot encoding representamos a palavras com vetores de 0 e 1. No count vector, substituimos isso por um vetor com a frequência de cada palavra no texto. Ele deixa de ser um vetor binário e passa a ser a frequência da palavra que apareceu no documento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C has 3 texts:\n",
      "t1 = The who is the band!\n",
      "t2 = who is the band?\n",
      "t3 = The band who plays the who.\n"
     ]
    }
   ],
   "source": [
    "C = ['The who is the band!', 'who is the band?', 'The band who plays the who.']\n",
    "\n",
    "print('C has %d texts:' % len(C))\n",
    "for i in range(len(C)):\n",
    "    print(f\"t{i+1} = {C[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V has 5 words: ['band', 'is', 'plays', 'the', 'who']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def get_tokens(text):\n",
    "    # ignore = ['a', 'the', 'is']\n",
    "    tokens = re.sub(\"[^\\w]\", \" \", text).split()\n",
    "    return [w.lower() for w in tokens]\n",
    "\n",
    "def tokenize(texts):\n",
    "    words = []\n",
    "    \n",
    "    for text in texts:\n",
    "        w = get_tokens(text)\n",
    "        words.extend(w)\n",
    "        words = sorted(list(set(words)))\n",
    "    \n",
    "    return words\n",
    "\n",
    "V = tokenize(C)\n",
    "print(f\"V has {len(V)} words: {V}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The who is the band! = [1. 1. 0. 2. 1.]\n",
      "who is the band? = [1. 1. 0. 1. 1.]\n",
      "The band who plays the who. = [1. 0. 1. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "for text in C:\n",
    "    words = get_tokens(text)\n",
    "    bag_vector = numpy.zeros(len(V))\n",
    "    \n",
    "    for w in words:\n",
    "        for i, word in enumerate(V):\n",
    "            if word == w:\n",
    "                bag_vector[i] += 1 # Modification\n",
    "                \n",
    "    print(f\"{text} = {numpy.array(bag_vector)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Text Vectorization Librarie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_corpus(corpus):\n",
    "    new_corpus = [doc.lower() for doc in corpus]\n",
    "    regex = r\"(?<!\\d)[\\!\\?.,;:-](?!\\d)\"\n",
    "    return [re.sub(regex, \"\", doc, 0) for doc in new_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the who is the band', 'who is the band', 'the band who plays the who']\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = pre_process_corpus(C)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   band  is  plays  the  who\n",
      "0     1   1      0    2    1\n",
      "1     1   1      0    1    1\n",
      "2     1   0      1    2    2\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "doc_term_matriz = vectorizer.fit_transform(corpus)\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(pd.DataFrame(doc_term_matriz.A, columns=terms).to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
